---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# btw <a href="https://posit-dev.github.io/btw/"><img src="man/figures/logo.png" align="right" height="138" alt="btw website" /></a>

> Give LLMs the context they need to help with your R code

<!-- badges: start -->
[![CRAN status](https://www.r-pkg.org/badges/version/btw)](https://CRAN.R-project.org/package=btw)
[![R-CMD-check](https://github.com/posit-dev/btw/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/posit-dev/btw/actions/workflows/R-CMD-check.yaml)
[![Codecov test coverage](https://codecov.io/gh/posit-dev/btw/graph/badge.svg)](https://app.codecov.io/gh/posit-dev/btw)
<!-- badges: end -->

## The Problem

Large Language Models are great at writing R code—until they need to understand *your* R environment. They don't know what data you're working with, which packages you have installed, or what functions are available. Without that context, their suggestions can be generic, outdated, or just plain wrong.

**btw** solves this by making it easy to describe your R environment to LLMs in plain text they can understand.

## Three Ways to Use btw

btw meets you wherever you are in your LLM workflow:

- **Copy-paste workflow**: Use `btw()` to gather context from your R session and paste it into ChatGPT, Claude, or any chat interface
- **Chat in your IDE**: Use `btw_client()` or `btw_app()` to chat with LLMs directly in R, with full access to your environment
- **Build custom apps**: Use `btw_tools()` to add a powerful toolkit to your own LLM-powered applications

## Installation

Install btw from CRAN:

```{r eval=FALSE}
install.packages("btw")
```

Or get the development version:

```{r eval=FALSE}
pak::pak("posit-dev/btw")
```

## Quick Start

```{r setup}
library(btw)
```

### Copy Context to Any Chat Interface

The `btw()` function gathers context and copies it to your clipboard:

```{r eval=FALSE}
# Describe a data frame
btw(mtcars)

# Include package documentation
btw(mtcars, "{dplyr}")

# Add help pages
btw(mtcars, "{dplyr}", ?dplyr::across)
```

```
✔ btw copied to the clipboard!
```

Paste the results into ChatGPT, Claude, or any LLM chat interface. The LLM now knows exactly what you're working with.

**Special context strings:**

- `btw("@platform_info")` — Your R version, OS, and locale
- `btw("@current_file")` — Contents of your current editor (RStudio/Positron)
- `btw("@installed_packages")` — List of installed packages
- `btw("./path/to/file.R")` — Contents of a file or directory

See `?btw_this.character` for the full list.

### Chat with LLMs Inside R

`btw_client()` gives you a chat interface with full access to your R environment:

```{r eval=FALSE}
chat <- btw_client(mtcars)
chat$chat("What's the average mpg for 6-cylinder cars?")
```

The LLM can explore your environment, read documentation, and even write files—all through natural conversation.

By default, `btw_client()` uses Claude (via Anthropic's API). Customize it:

```{r eval=FALSE}
# Use a local model with Ollama
chat <- btw_client(client = ellmer::chat_ollama(model = "llama3.1:8b"))

# Set a default in your .Rprofile
options(btw.chat_client = ellmer::chat_ollama(model = "llama3.1:8b"))
```

Or launch a Shiny chat interface:

```{r eval=FALSE}
btw_app()
```

**Project context with btw.md:**

Create a `btw.md` file in your project to set defaults and provide project-specific instructions. btw will automatically include this context in every chat:

```markdown
---
client:
  provider: anthropic
  model: claude-3-5-sonnet-20241022
tools: [docs, env, files]
---

This project uses the tidyverse. Prefer dplyr and ggplot2 for data analysis.
```

Use `use_btw_md()` to create a template in your project.

### Build LLM-Powered Applications

`btw_tools()` registers a powerful toolkit with any ellmer chat:

```{r eval=FALSE}
library(ellmer)

chat <- chat_anthropic()
chat$set_tools(btw_tools())

# Now the LLM can explore your environment
chat$chat("What data frames are available in my environment?")
```

Choose specific tool groups for granular control:

```{r eval=FALSE}
# Only documentation and environment tools
chat$set_tools(btw_tools(c("docs", "env")))

# Everything except file writing
chat$set_tools(btw_tools(exclude = "files"))
```

Available tool groups: `docs`, `env`, `files`, `ide`, `search`, `session`, `web`.

## Learn More

- **Website**: <https://posit-dev.github.io/btw/>
- **Getting help**: <https://github.com/posit-dev/btw/issues>
- **ellmer package**: <https://github.com/tidyverse/ellmer> (LLM chat client framework)

## Citation

If you use btw in your research or work, please cite it:

```{r eval=FALSE}
citation("btw")
```

## Code of Conduct

Please note that the btw project is released with a [Contributor Code of Conduct](https://posit-dev.github.io/btw/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.

